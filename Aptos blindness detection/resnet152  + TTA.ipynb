{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nimport time\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nimport torch\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.optim import lr_scheduler\nimport os\n\ndevice = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\nimport matplotlib.pyplot as plt\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTrain(Dataset):\n    \n    def __init__(self, csv_file, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n        \n        \n    def __getitem__(self, idx):\n        label = torch.tensor(self.data.loc[idx, \"diagnosis\"])\n        img_name = os.path.join('/kaggle/input/train_images', \n                                self.data.loc[idx, 'id_code'] + '.png')\n        image = Image.open(img_name)\n       # image = image.resize((256,256), resample=Image.BILINEAR)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        sample = {'image': image, \"label\": label}\n            \n        return sample\n        \n        ","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTest(Dataset):\n    \n    def __init__(self, csv_file, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n        \n        \n    def __getitem__(self, idx):\n        img_name = os.path.join('/kaggle/input/test_images', \n                                self.data.loc[idx, 'id_code'] + '.png')\n        image = Image.open(img_name)\n       # image = image.resize((256,256), resample=Image.BILINEAR)\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        return {'image': image}","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_photo(image, label):\n    \"\"\"Show image with landmarks\"\"\"\n    plt.imshow(image)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n    print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[0][\"image\"].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(device)","execution_count":7,"outputs":[{"output_type":"stream","text":"cuda:0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torchvision.models.resnet152(pretrained=False)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(2048, 1)\n\nmodel = model.to(device)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = RetinopathyDatasetTrain(csv_file = \"/kaggle/input/train.csv\", transform = transform)\ndataloader = torch.utils.data.DataLoader(dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\nplist = [\n         {'params': model.layer4.parameters(), 'lr': 1e-4, 'weight': 0.001},\n         {'params': model.fc.parameters(), 'lr': 1e-3}\n         ]\n\noptimizer = optim.Adam(plist, lr=0.001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=10)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"since = time.time()\ncriterion = nn.MSELoss()\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n    print('-' * 10)\n    scheduler.step()\n    model.train()\n    running_loss = 0.0\n    tk0 = tqdm(dataloader, total=int(len(dataloader)))\n    counter = 0\n    for bi, d in enumerate(tk0):\n        inputs = d[\"image\"]\n        labels = d[\"label\"].view(-1, 1)\n        inputs = inputs.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.float)\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(True):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n        counter += 1\n        tk0.set_postfix(loss=(running_loss / (counter * dataloader.batch_size)))\n    epoch_loss = running_loss / len(dataloader)\n    print('Training Loss: {:.4f}'.format(epoch_loss))\n\ntime_elapsed = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\ntorch.save(model.state_dict(), \"model.bin\")\n        ","execution_count":12,"outputs":[{"output_type":"stream","text":"\r  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Epoch 0/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.20it/s, loss=1.37]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 21.9540\nEpoch 1/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.01s/it, loss=1.32]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 21.1083\nEpoch 2/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.06it/s, loss=1.25]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 19.9964\nEpoch 3/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.48it/s, loss=1.28]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 20.4422\nEpoch 4/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.29s/it, loss=1.24]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 19.8392\nEpoch 5/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.17it/s, loss=1.16]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 18.6308\nEpoch 6/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:56<00:00,  1.38it/s, loss=1.23]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 19.7050\nEpoch 7/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.08it/s, loss=1.05]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 16.7552\nEpoch 8/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.15it/s, loss=1.05]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 16.7874\nEpoch 9/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.29s/it, loss=1.01]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 16.1241\nEpoch 10/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:54<00:00,  1.29s/it, loss=0.991]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 15.8508\nEpoch 11/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.29s/it, loss=1.02] \n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 16.2542\nEpoch 12/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.32it/s, loss=0.987]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 15.7971\nEpoch 13/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:56<00:00,  1.20it/s, loss=0.996]\n  0%|          | 0/229 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Training Loss: 15.9358\nEpoch 14/14\n----------\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 229/229 [04:55<00:00,  1.09it/s, loss=0.964]\n","name":"stderr"},{"output_type":"stream","text":"Training Loss: 15.4257\nTraining complete in 73m 56s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = RetinopathyDatasetTest(csv_file = \"/kaggle/input/test.csv\", transform = transform)\n","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds1 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds1[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":20,"outputs":[{"output_type":"stream","text":"CPU times: user 4.28 s, sys: 768 ms, total: 5.05 s\nWall time: 53.2 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds2 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds2[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds3 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds3[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds4 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds4[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds5 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds5[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds6 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds6[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds7 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds7[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds8 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds8[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds9 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds9[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\n# Prediction\nwith torch.no_grad():\n    test_preds10 = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds10[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = (test_preds1 + test_preds2 + test_preds3 + test_preds4 + test_preds5\n             + test_preds6 + test_preds7 + test_preds8 + test_preds9 + test_preds10) / 10.0","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncoef = [0.5, 1.5, 2.5, 3.5]\n\nfor i, pred in enumerate(test_preds):\n    if pred < coef[0]:\n        test_preds[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        test_preds[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        test_preds[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        test_preds[i] = 3\n    else:\n        test_preds[i] = 4\n\n","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsample = pd.read_csv(\"../input/sample_submission.csv\")\nsample.diagnosis = test_preds.astype(int)\nsample.to_csv(\"submission.csv\", index=False)","execution_count":33,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}