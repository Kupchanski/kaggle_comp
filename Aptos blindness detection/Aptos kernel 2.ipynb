{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom PIL import Image, ImageFile\nimport cv2\nfrom torch.utils.data import Dataset\nimport torch\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.optim import lr_scheduler\nimport os\nimport albumentations\nfrom albumentations import torch as AT\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n\n\ndevice = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def circle_crop(img, sigmaX=10):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = cv2.imread(img)\n    img = crop_image_from_gray(img)    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n    return img ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTrain(Dataset):\n    \n    def __init__(self, csv_file, transform=None):\n        self.data = csv_file\n        self.transform = transform\n        self.image_files_list = [f'../input/aptos2019-blindness-detection/train_images/{i}.png' for i in self.data['id_code'].values]\n        \n    def __len__(self):\n        return len(self.image_files_list)\n\n    def __getitem__(self, idx):\n        img_name = self.image_files_list[idx]\n        #img = cv2.imread(img_name)\n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = circle_crop(img_name)\n        image = self.transform(image=img)\n        image = image['image']\n        label = self.data.loc[idx, 'diagnosis']\n        return image, label\n\n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTest(Dataset):\n    \n    def __init__(self, csv_file, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        self.image_files_list = [f'../input/aptos2019-blindness-detection/test_images/{i}.png' for i in self.data['id_code'].values]\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = self.image_files_list[idx]\n        #img = cv2.imread(img_name)\n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = circle_crop(img_name)\n        image = self.transform(image=img)\n        image = image['image']\n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transforms = albumentations.Compose([\n    albumentations.Resize(224, 224),\n    albumentations.HorizontalFlip(),\n    albumentations.RandomBrightness(),\n    albumentations.ShiftScaleRotate(rotate_limit=15, scale_limit=0.10),\n    albumentations.JpegCompression(80),\n    albumentations.HueSaturationValue(),\n    albumentations.Normalize(),\n    AT.ToTensor()\n    ])\ntransforms_test = albumentations.Compose([\n    albumentations.Resize(224, 224),\n    albumentations.Normalize(),\n    AT.ToTensor()\n    ])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torchvision.models.resnet101(pretrained=False)\nmodel.load_state_dict(torch.load(\"../input/pytorch-pretrained-models/resnet101-5d3b4d8f.pth\"))\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(2048, 1)\n\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/aptos2019-blindness-detection/train.csv\")\ndataset = RetinopathyDatasetTrain(csv_file = train, transform = transforms)\n\ntr, val = train_test_split(train.diagnosis, stratify=train.diagnosis, test_size=0.1)\ntrain_sampler = SubsetRandomSampler(list(tr.index))\nvalid_sampler = SubsetRandomSampler(list(val.index))\nbatch_size = 16\nnum_workers = 4\n# prepare data loaders (combine dataset and sampler)\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\nvalidloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n\n\n\"\"\"plist = [\n         {'params': model.layer4.parameters(), 'lr': 1e-4, 'weight': 0.001},\n         {'params': model.fc.parameters(), 'lr': 1e-3}\n         ]\n\"\"\"\n\ncriterion = nn.BCEWithLogitsLoss()\ncriterion_2 = nn.MSELoss()\noptimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.99)\noptimizer_2 = optim.Adam(model.fc.parameters(), lr=0.001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_loss_min = np.Inf\ncriterion = nn.MSELoss()\npatience = 5\n# current number of epochs, where validation loss didn't increase\np = 0\n# whether training should be stopped\nstop = False\n\n# number of epochs to train the model\nn_epochs = 2\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n\n    train_loss = []\n    train_auc = []\n\n    for i, (data, target) in enumerate(dataloader):\n\n        data, target = data.cuda(), target.cuda().view(-1,1)\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target.float())\n        train_loss.append(loss.item())        \n        #a = target.data.cpu().numpy()\n        #b = output[:,-1].detach().cpu().numpy()\n        # train_auc.append(roc_auc_score(a, b))\n        loss.backward()\n        optimizer.step()\n        print(\"train step\")\n    \n    model.eval()\n    val_loss = []\n    val_auc = []\n    for i, (data, target) in enumerate(validloader):\n        data, target = data.cuda(), target.cuda().view(-1,1)\n        output = model(data)\n        loss = criterion(output, target.float())\n        val_loss.append(loss.item()) \n        print(\"val step\")\n        #a = target.data.cpu().numpy()\n        #b = output[:,-1].detach().cpu().numpy()\n        # val_auc.append(roc_auc_score(a, b))\n\n    # print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}, train auc: {np.mean(train_auc):.4f}, valid auc: {np.mean(val_auc):.4f}')\n    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}.')\n    \n    valid_loss = np.mean(val_loss)\n    scheduler.step(valid_loss)\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model.pt')\n        valid_loss_min = valid_loss\n        p = 0\n\n    # check if validation loss didn't improve\n    if valid_loss > valid_loss_min:\n        p += 1\n        print(f'{p} epochs of increasing val loss')\n        if p > patience:\n            print('Stopping training')\n            stop = True\n            break        \n            \n    if stop:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save({'arch': 'resnet101',\n            'state_dict': model.state_dict(), \n            'class_to_idx': model.class_to_idx}, \n            'classifier.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"\"\"\"since = time.time()\n\ncriterion = nn.MSELoss()\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n    print('-' * 10)\n    scheduler.step()\n    model.train()\n    running_loss = 0.0\n    tk0 = tqdm(dataloader, total=int(len(dataloader)))\n    counter = 0\n    for bi, (inputs, labels) in enumerate(tk0):\n        inputs = inputs.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.float).view(-1,1)\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(True):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n        counter += 1\n        tk0.set_postfix(loss=(running_loss / (counter * dataloader.batch_size)))\n    epoch_loss = running_loss / len(dataloader)\n    print('Training Loss: {:.4f}'.format(epoch_loss))\n\ntime_elapsed = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\ntorch.save(model.state_dict(), \"model.bin\")\"\"\"\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = RetinopathyDatasetTest(csv_file = \"/kaggle/input/aptos2019-blindness-detection/test.csv\", transform = transforms_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tta_func(model):\n    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n    with torch.no_grad():\n        predict = np.zeros((len(test_dataset), 1))\n\n        for i, image in enumerate(test_dataloader):\n            pred = model(image.to(device))   \n            predict[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n    return predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict1 = tta_func(model)\npredict2 = tta_func(model)\npredict3 = tta_func(model)\npredict4 = tta_func(model)\npredict5 = tta_func(model)\npredict6 = tta_func(model)\npredict7 = tta_func(model)\npredict8 = tta_func(model)\npredict9 = tta_func(model)\npredict10 = tta_func(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = (predict1 + predict2 + predict3 + predict4 + predict5\n             + predict6 + predict7 + predict8+ predict9 + predict10) /10.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncoef = [0.5, 1.5, 2.5, 3.5]\n\nfor i, pred in enumerate(test_preds):\n    if pred < coef[0]:\n        test_preds[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        test_preds[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        test_preds[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        test_preds[i] = 3\n    else:\n        test_preds[i] = 4\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsample = pd.read_csv(\"../input/aptos2019-blindness-detection/sample_submission.csv\")\nsample.diagnosis = test_preds.astype(int)\nsample.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}