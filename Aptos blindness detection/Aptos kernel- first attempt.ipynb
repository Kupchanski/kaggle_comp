{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nimport time\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nimport torch\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.optim import lr_scheduler\nimport os\n\ndevice = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\nimport matplotlib.pyplot as plt\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTrain(Dataset):\n    \n    def __init__(self, csv_file, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n        \n        \n    def __getitem__(self, idx):\n        label = torch.tensor(self.data.loc[idx, \"diagnosis\"])\n        img_name = os.path.join('/kaggle/input/train_images', \n                                self.data.loc[idx, 'id_code'] + '.png')\n        image = Image.open(img_name)\n       # image = image.resize((256,256), resample=Image.BILINEAR)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        sample = {'image': image, \"label\": label}\n            \n        return sample\n        \n        ","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTest(Dataset):\n    \n    def __init__(self, csv_file, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n        \n        \n    def __getitem__(self, idx):\n        img_name = os.path.join('/kaggle/input/test_images', \n                                self.data.loc[idx, 'id_code'] + '.png')\n        image = Image.open(img_name)\n       # image = image.resize((256,256), resample=Image.BILINEAR)\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        return {'image': image}","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_photo(image, label):\n    \"\"\"Show image with landmarks\"\"\"\n    plt.imshow(image)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n    print(label)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[0][\"image\"].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torchvision.models.resnet50(pretrained=False)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(2048, 1)\n\nmodel = model.to(device)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = RetinopathyDatasetTrain(csv_file = \"/kaggle/input/train.csv\", transform = transform)\ndataloader = torch.utils.data.DataLoader(dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\nplist = [\n         {'params': model.layer4.parameters(), 'lr': 1e-4, 'weight': 0.001},\n         {'params': model.fc.parameters(), 'lr': 1e-3}\n         ]\n\noptimizer = optim.Adam(plist, lr=0.001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=10)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"since = time.time()\ncriterion = nn.MSELoss()\nnum_epochs = 15\n\nfor epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n    print('-' * 10)\n    scheduler.step()\n    model.train()\n    running_loss = 0.0\n    counter = 0\n    for _, sample in enumerate(dataloader):\n        image = sample[\"image\"]\n        label = sample[\"label\"].view(-1,1)\n        image = image.to(device, dtype=torch.float)\n        label = label.to(device, dtype=torch.float)\n        optimizer.zero_grad()\n        \n        output = model(image)\n        loss = criterion(output, label)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * image.size(0)\n        counter +=1\n        epoch_loss = running_loss / len(dataloader)\n        print('Training Loss: {:.4f}'.format(epoch_loss))\ntime_elapsed = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\ntorch.save(model.state_dict(), \"model.bin\")\n        ","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 0/14\n----------\nTraining Loss: 0.1310\nTraining Loss: 0.2566\nTraining Loss: 0.4394\nTraining Loss: 0.5041\nTraining Loss: 0.6224\nTraining Loss: 0.7543\nTraining Loss: 0.9006\nTraining Loss: 1.0266\nTraining Loss: 1.1013\nTraining Loss: 1.2458\nTraining Loss: 1.4045\nTraining Loss: 1.4569\nTraining Loss: 1.5790\nTraining Loss: 1.6598\nTraining Loss: 1.7957\nTraining Loss: 1.9286\nTraining Loss: 2.0461\nTraining Loss: 2.0984\nTraining Loss: 2.1522\nTraining Loss: 2.3580\nTraining Loss: 2.4365\nTraining Loss: 2.5667\nTraining Loss: 2.6585\nTraining Loss: 2.7590\nTraining Loss: 2.8868\nTraining Loss: 3.0655\nTraining Loss: 3.1259\nTraining Loss: 3.2094\nTraining Loss: 3.3906\nTraining Loss: 3.4774\nTraining Loss: 3.6364\nTraining Loss: 3.7882\nTraining Loss: 3.9240\nTraining Loss: 4.0723\nTraining Loss: 4.1401\nTraining Loss: 4.2491\nTraining Loss: 4.3868\nTraining Loss: 4.5211\nTraining Loss: 4.6799\nTraining Loss: 4.7804\nTraining Loss: 4.8559\nTraining Loss: 4.9081\nTraining Loss: 5.0087\nTraining Loss: 5.1174\nTraining Loss: 5.1655\nTraining Loss: 5.2549\nTraining Loss: 5.3221\nTraining Loss: 5.4733\nTraining Loss: 5.5617\nTraining Loss: 5.6309\nTraining Loss: 5.7296\nTraining Loss: 5.8500\nTraining Loss: 5.9866\nTraining Loss: 6.1322\nTraining Loss: 6.1798\nTraining Loss: 6.2385\nTraining Loss: 6.3370\nTraining Loss: 6.5718\nTraining Loss: 6.8238\nTraining Loss: 6.8796\nTraining Loss: 7.0110\nTraining Loss: 7.1132\nTraining Loss: 7.2369\nTraining Loss: 7.3633\nTraining Loss: 7.4672\nTraining Loss: 7.5764\nTraining Loss: 7.7511\nTraining Loss: 7.8898\nTraining Loss: 8.0052\nTraining Loss: 8.1350\nTraining Loss: 8.3357\nTraining Loss: 8.5065\nTraining Loss: 8.6062\nTraining Loss: 8.6907\nTraining Loss: 8.9941\nTraining Loss: 9.2212\nTraining Loss: 9.3582\nTraining Loss: 9.4229\nTraining Loss: 9.5404\nTraining Loss: 9.6841\nTraining Loss: 9.7460\nTraining Loss: 9.9043\nTraining Loss: 9.9789\nTraining Loss: 10.2148\nTraining Loss: 10.3381\nTraining Loss: 10.3757\nTraining Loss: 10.4552\nTraining Loss: 10.5800\nTraining Loss: 10.6710\nTraining Loss: 10.8139\nTraining Loss: 10.8764\nTraining Loss: 10.9664\nTraining Loss: 11.0574\nTraining Loss: 11.1116\nTraining Loss: 11.2385\nTraining Loss: 11.4039\nTraining Loss: 11.5339\nTraining Loss: 11.6569\nTraining Loss: 11.8064\nTraining Loss: 11.9284\nTraining Loss: 12.0160\nTraining Loss: 12.0995\nTraining Loss: 12.2232\nTraining Loss: 12.2841\nTraining Loss: 12.3987\nTraining Loss: 12.5250\nTraining Loss: 12.7168\nTraining Loss: 12.8030\nTraining Loss: 12.9047\nTraining Loss: 13.0461\nTraining Loss: 13.1095\nTraining Loss: 13.1905\nTraining Loss: 13.3173\nTraining Loss: 13.4492\nTraining Loss: 13.5116\nTraining Loss: 13.6009\nTraining Loss: 13.6644\nTraining Loss: 13.7801\nTraining Loss: 13.8998\nTraining Loss: 14.0320\nTraining Loss: 14.1226\nTraining Loss: 14.1856\nTraining Loss: 14.2570\nTraining Loss: 14.3168\nTraining Loss: 14.4091\nTraining Loss: 14.5199\nTraining Loss: 14.6472\nTraining Loss: 14.7572\nTraining Loss: 14.8445\nTraining Loss: 14.9510\nTraining Loss: 15.0093\nTraining Loss: 15.0858\nTraining Loss: 15.1612\nTraining Loss: 15.2505\nTraining Loss: 15.3734\nTraining Loss: 15.5418\nTraining Loss: 15.6148\nTraining Loss: 15.7360\nTraining Loss: 15.8533\nTraining Loss: 15.9373\nTraining Loss: 16.1134\nTraining Loss: 16.2517\nTraining Loss: 16.3211\nTraining Loss: 16.3578\nTraining Loss: 16.5171\nTraining Loss: 16.7301\nTraining Loss: 16.9237\nTraining Loss: 16.9912\nTraining Loss: 17.0594\nTraining Loss: 17.2208\nTraining Loss: 17.3355\nTraining Loss: 17.4415\nTraining Loss: 17.5014\nTraining Loss: 17.5838\nTraining Loss: 17.7844\nTraining Loss: 18.0177\nTraining Loss: 18.0875\nTraining Loss: 18.1528\nTraining Loss: 18.2466\nTraining Loss: 18.3107\nTraining Loss: 18.4295\nTraining Loss: 18.5578\nTraining Loss: 18.6741\nTraining Loss: 18.7759\nTraining Loss: 18.9462\nTraining Loss: 19.0503\nTraining Loss: 19.1385\nTraining Loss: 19.2101\nTraining Loss: 19.2654\nTraining Loss: 19.3874\nTraining Loss: 19.4838\nTraining Loss: 19.5426\nTraining Loss: 19.7009\nTraining Loss: 19.7511\nTraining Loss: 19.9336\nTraining Loss: 20.0597\nTraining Loss: 20.1387\nTraining Loss: 20.2882\nTraining Loss: 20.3786\nTraining Loss: 20.4868\nTraining Loss: 20.5574\nTraining Loss: 20.6094\nTraining Loss: 20.6731\nTraining Loss: 20.7539\nTraining Loss: 20.8475\nTraining Loss: 20.9447\nTraining Loss: 21.0062\nTraining Loss: 21.1888\nTraining Loss: 21.2694\nTraining Loss: 21.3455\nTraining Loss: 21.4411\nTraining Loss: 21.5397\nTraining Loss: 21.6165\nTraining Loss: 21.7368\nTraining Loss: 21.8582\nTraining Loss: 21.9110\nTraining Loss: 22.0411\nTraining Loss: 22.1399\nTraining Loss: 22.2559\nTraining Loss: 22.3935\nTraining Loss: 22.4653\nTraining Loss: 22.5496\nTraining Loss: 22.6246\nTraining Loss: 22.6668\nTraining Loss: 22.7955\nTraining Loss: 22.9325\nTraining Loss: 22.9991\nTraining Loss: 23.1192\nTraining Loss: 23.2356\nTraining Loss: 23.3881\nTraining Loss: 23.4643\nTraining Loss: 23.5043\nTraining Loss: 23.5844\nTraining Loss: 23.6990\nTraining Loss: 23.8807\nTraining Loss: 23.9336\nTraining Loss: 24.0084\nTraining Loss: 24.0874\nTraining Loss: 24.1983\nTraining Loss: 24.3013\nTraining Loss: 24.3445\nTraining Loss: 24.4955\nTraining Loss: 24.5970\nTraining Loss: 24.7803\nTraining Loss: 24.8551\nTraining Loss: 24.9609\nTraining Loss: 25.0539\nTraining Loss: 25.1635\nTraining Loss: 25.2544\nEpoch 1/14\n----------\nTraining Loss: 0.1028\nTraining Loss: 0.1959\nTraining Loss: 0.2353\nTraining Loss: 0.3741\nTraining Loss: 0.5311\nTraining Loss: 0.5831\nTraining Loss: 0.6951\nTraining Loss: 0.8904\nTraining Loss: 1.0202\nTraining Loss: 1.1548\nTraining Loss: 1.3059\nTraining Loss: 1.3247\nTraining Loss: 1.4977\nTraining Loss: 1.5754\nTraining Loss: 1.6347\nTraining Loss: 1.7360\nTraining Loss: 1.8564\nTraining Loss: 1.9638\nTraining Loss: 2.1091\nTraining Loss: 2.2372\nTraining Loss: 2.3343\nTraining Loss: 2.4059\nTraining Loss: 2.4887\nTraining Loss: 2.6242\nTraining Loss: 2.7885\nTraining Loss: 2.8869\nTraining Loss: 3.0034\nTraining Loss: 3.0995\nTraining Loss: 3.2166\nTraining Loss: 3.3468\nTraining Loss: 3.4196\nTraining Loss: 3.5647\nTraining Loss: 3.6820\nTraining Loss: 3.7951\nTraining Loss: 3.9718\nTraining Loss: 4.1537\nTraining Loss: 4.2961\nTraining Loss: 4.3644\nTraining Loss: 4.4732\nTraining Loss: 4.5733\nTraining Loss: 4.6354\nTraining Loss: 4.7932\nTraining Loss: 4.8905\nTraining Loss: 5.0535\nTraining Loss: 5.1327\nTraining Loss: 5.2295\nTraining Loss: 5.3389\nTraining Loss: 5.4438\nTraining Loss: 5.6022\nTraining Loss: 5.7065\nTraining Loss: 5.7856\nTraining Loss: 5.8457\nTraining Loss: 5.9023\nTraining Loss: 6.0242\nTraining Loss: 6.1270\nTraining Loss: 6.1991\nTraining Loss: 6.3516\nTraining Loss: 6.4170\nTraining Loss: 6.4967\nTraining Loss: 6.6443\nTraining Loss: 6.7081\nTraining Loss: 6.8171\nTraining Loss: 6.9274\nTraining Loss: 7.0559\nTraining Loss: 7.1687\nTraining Loss: 7.2280\nTraining Loss: 7.3731\nTraining Loss: 7.4972\nTraining Loss: 7.6339\nTraining Loss: 7.7644\nTraining Loss: 7.8360\nTraining Loss: 7.9276\nTraining Loss: 8.0493\nTraining Loss: 8.1705\nTraining Loss: 8.2441\nTraining Loss: 8.3254\nTraining Loss: 8.3905\nTraining Loss: 8.4396\nTraining Loss: 8.7054\nTraining Loss: 8.7688\nTraining Loss: 8.8513\nTraining Loss: 8.9830\nTraining Loss: 9.0875\nTraining Loss: 9.1771\nTraining Loss: 9.2183\nTraining Loss: 9.2712\nTraining Loss: 9.3500\nTraining Loss: 9.4732\nTraining Loss: 9.5252\nTraining Loss: 9.6336\nTraining Loss: 9.8023\nTraining Loss: 9.8665\nTraining Loss: 9.9513\nTraining Loss: 10.1056\nTraining Loss: 10.2033\nTraining Loss: 10.3523\nTraining Loss: 10.4366\nTraining Loss: 10.5172\nTraining Loss: 10.5611\nTraining Loss: 10.7299\nTraining Loss: 10.9069\nTraining Loss: 11.0409\nTraining Loss: 11.0868\nTraining Loss: 11.2591\nTraining Loss: 11.3851\nTraining Loss: 11.4803\nTraining Loss: 11.5314\nTraining Loss: 11.6269\nTraining Loss: 11.7206\nTraining Loss: 11.7800\nTraining Loss: 11.9099\nTraining Loss: 11.9754\nTraining Loss: 12.0765\nTraining Loss: 12.1555\nTraining Loss: 12.2366\nTraining Loss: 12.3366\nTraining Loss: 12.4882\nTraining Loss: 12.6039\nTraining Loss: 12.7417\nTraining Loss: 12.8168\nTraining Loss: 12.8826\nTraining Loss: 12.9689\nTraining Loss: 13.0168\nTraining Loss: 13.1485\nTraining Loss: 13.3630\nTraining Loss: 13.4394\nTraining Loss: 13.4942\nTraining Loss: 13.5404\nTraining Loss: 13.6148\nTraining Loss: 13.7164\nTraining Loss: 13.7371\nTraining Loss: 13.7955\nTraining Loss: 13.8999\nTraining Loss: 13.9448\n","name":"stdout"},{"output_type":"stream","text":"Training Loss: 14.0270\nTraining Loss: 14.0927\nTraining Loss: 14.1576\nTraining Loss: 14.2190\nTraining Loss: 14.2839\nTraining Loss: 14.3612\nTraining Loss: 14.4727\nTraining Loss: 14.5127\nTraining Loss: 14.5595\nTraining Loss: 14.6736\nTraining Loss: 14.7456\nTraining Loss: 14.8002\nTraining Loss: 14.9878\nTraining Loss: 15.0969\nTraining Loss: 15.2668\nTraining Loss: 15.3622\nTraining Loss: 15.3971\nTraining Loss: 15.4787\nTraining Loss: 15.5541\nTraining Loss: 15.6312\nTraining Loss: 15.6749\nTraining Loss: 15.7281\nTraining Loss: 15.8155\nTraining Loss: 15.9108\nTraining Loss: 15.9798\nTraining Loss: 16.0772\nTraining Loss: 16.1882\nTraining Loss: 16.3481\nTraining Loss: 16.4518\nTraining Loss: 16.5602\nTraining Loss: 16.6125\nTraining Loss: 16.7075\nTraining Loss: 16.7983\nTraining Loss: 16.8711\nTraining Loss: 17.0022\nTraining Loss: 17.0722\nTraining Loss: 17.1406\nTraining Loss: 17.2111\nTraining Loss: 17.3402\nTraining Loss: 17.4699\nTraining Loss: 17.6074\nTraining Loss: 17.6996\nTraining Loss: 17.8003\nTraining Loss: 17.8940\nTraining Loss: 18.0003\nTraining Loss: 18.0897\nTraining Loss: 18.1760\nTraining Loss: 18.2416\nTraining Loss: 18.3603\nTraining Loss: 18.4652\nTraining Loss: 18.4919\nTraining Loss: 18.5529\nTraining Loss: 18.6060\nTraining Loss: 18.7220\nTraining Loss: 18.8892\nTraining Loss: 18.9839\nTraining Loss: 19.1302\nTraining Loss: 19.2390\nTraining Loss: 19.3322\nTraining Loss: 19.4275\nTraining Loss: 19.4567\nTraining Loss: 19.4879\nTraining Loss: 19.5518\nTraining Loss: 19.6520\nTraining Loss: 19.7298\nTraining Loss: 19.7780\nTraining Loss: 19.8526\nTraining Loss: 19.9386\nTraining Loss: 20.0057\nTraining Loss: 20.1010\nTraining Loss: 20.1418\nTraining Loss: 20.2554\nTraining Loss: 20.3729\nTraining Loss: 20.4561\nTraining Loss: 20.5039\nTraining Loss: 20.5728\nTraining Loss: 20.6921\nTraining Loss: 20.7662\nTraining Loss: 20.8320\nTraining Loss: 20.8852\nTraining Loss: 20.9598\nTraining Loss: 21.0436\nTraining Loss: 21.1759\nTraining Loss: 21.2586\nTraining Loss: 21.3930\nTraining Loss: 21.4679\nTraining Loss: 21.5643\nTraining Loss: 21.7152\nTraining Loss: 21.8208\nTraining Loss: 21.9845\nTraining Loss: 22.0626\nTraining Loss: 22.1700\nTraining Loss: 22.2501\nTraining Loss: 22.3276\nTraining Loss: 22.3890\nEpoch 2/14\n----------\nTraining Loss: 0.1339\nTraining Loss: 0.2303\nTraining Loss: 0.3136\nTraining Loss: 0.4555\nTraining Loss: 0.5316\nTraining Loss: 0.6536\nTraining Loss: 0.7012\nTraining Loss: 0.8019\nTraining Loss: 0.8750\nTraining Loss: 0.9198\nTraining Loss: 0.9586\nTraining Loss: 1.1971\nTraining Loss: 1.2666\nTraining Loss: 1.3343\nTraining Loss: 1.3995\nTraining Loss: 1.4979\nTraining Loss: 1.6074\nTraining Loss: 1.6935\nTraining Loss: 1.8008\nTraining Loss: 1.8367\nTraining Loss: 1.9934\nTraining Loss: 2.0883\nTraining Loss: 2.1821\nTraining Loss: 2.3015\nTraining Loss: 2.4259\nTraining Loss: 2.4946\nTraining Loss: 2.6128\nTraining Loss: 2.7150\nTraining Loss: 2.8190\nTraining Loss: 2.8772\nTraining Loss: 2.8932\nTraining Loss: 3.0192\nTraining Loss: 3.1573\nTraining Loss: 3.2326\nTraining Loss: 3.2978\nTraining Loss: 3.3784\nTraining Loss: 3.5300\nTraining Loss: 3.5920\nTraining Loss: 3.6550\nTraining Loss: 3.7804\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = RetinopathyDatasetTest(csv_file = \"/kaggle/input/test.csv\", transform = transform)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = True, num_workers = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    test_preds = np.zeros((len(test_dataset), 1))\n    \n    for i, image in enumerate(test_dataloader):\n        image = image[\"image\"]\n        pred = model(image.to(device))\n        test_preds1[i * 16:(i + 1) * 16] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n\nsample = pd.read_csv(\"../input/sample_submission.csv\")\nsample.diagnosis = test_preds.astype(int)\nsample.to_csv(\"submission.csv\", index=False)\n        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}