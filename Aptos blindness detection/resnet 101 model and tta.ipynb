{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n\nImportant: in kernel-only competitions we can't use internet connections. So I use pretrained models from here: https://www.kaggle.com/bminixhofer/pytorch-pretrained-image-models"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time \nimport tqdm\nfrom PIL import Image\ntrain_on_gpu = True\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\nimport copy\nimport cv2\nimport albumentations\nfrom albumentations import torch as AT","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntest = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\nsample_submission = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n\nold_train = pd.read_csv('../input/diabetic-retinopathy-resized/trainLabels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['diagnosis'].value_counts().plot(kind='bar');\nplt.title('Class counts');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a slight disbalance in data."},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"fig = plt.figure(figsize=(25, 16))\n# display 10 images from each class\nfor class_id in sorted(old_train['level'].unique()):\n    for i, (idx, row) in enumerate(old_train.loc[old_train['level'] == class_id].sample(10).iterrows()):\n        ax = fig.add_subplot(5, 10, class_id * 10 + i + 1, xticks=[], yticks=[])\n        im = Image.open(f'../input/diabetic-retinopathy-resized/resized_train/resized_train/{row[\"image\"]}.jpeg')\n        plt.imshow(im)\n        ax.set_title(f'Label: {level}')\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Personally I see little differences between images"},{"metadata":{},"cell_type":"markdown","source":"## Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\ndef prepare_labels(y):\n    # From here: https://www.kaggle.com/pestipeti/keras-cnn-starter\n    values = np.array(y)\n    label_encoder = LabelEncoder()\n    integer_encoded = label_encoder.fit_transform(values)\n\n    onehot_encoder = OneHotEncoder(sparse=False)\n    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n\n    y = onehot_encoded\n    return y, label_encoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y, le = prepare_labels(train['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def circle_crop(img, sigmaX=10):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = cv2.imread(img)\n    img = crop_image_from_gray(img)    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n    return img ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GlassDataset(Dataset):\n    def __init__(self, df, datatype='train', transform = transforms.Compose([transforms.CenterCrop(32),transforms.ToTensor()]), y = None):\n        self.df = df\n        self.datatype = datatype\n        if self.datatype == 'train':\n            self.image_files_list = [f'../input/aptos2019-blindness-detection/{self.datatype}_images/{i}.png' for i in df['id_code'].values]\n            self.labels = y\n        else:\n            self.image_files_list = [f'../input/aptos2019-blindness-detection/{self.datatype}_images/{i}.png' for i in df['id_code'].values]\n            self.labels = np.zeros((df.shape[0], 5))\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_files_list)\n\n    def __getitem__(self, idx):\n        img_name = self.image_files_list[idx]\n        img = cv2.imread(img_name)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        image = self.transform(image=img)\n        image = image['image']\n\n        img_name_short = self.image_files_list[idx].split('.')[0]\n\n        label = self.labels[idx]\n        if self.datatype == 'test':\n            return image, label, img_name\n        else:\n            return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_transforms = albumentations.Compose([\n    albumentations.Resize(224, 224),\n    albumentations.HorizontalFlip(),\n    albumentations.RandomBrightness(),\n    albumentations.ShiftScaleRotate(rotate_limit=15, scale_limit=0.10),\n    albumentations.JpegCompression(80),\n    albumentations.HueSaturationValue(),\n    albumentations.Normalize(),\n    AT.ToTensor()\n    ])\ndata_transforms_test = albumentations.Compose([\n    albumentations.Resize(224, 224),\n    albumentations.Normalize(),\n    AT.ToTensor()\n    ])\n\n\ndataset = GlassDataset(df=train, datatype='train', transform=data_transforms, y=y)\ntest_set = GlassDataset(df=test, datatype='test', transform=data_transforms_test)\ntr, val = train_test_split(train.diagnosis, stratify=train.diagnosis, test_size=0.1)\ntrain_sampler = SubsetRandomSampler(list(tr.index))\nvalid_sampler = SubsetRandomSampler(list(val.index))\nbatch_size = 16\nnum_workers = 0\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=num_workers)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_set = GlassDataset(df=test, datatype='test', transform=data_transforms_test)\n#test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=num_workers)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"../input/pretrained-pytorch-models\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_conv = torchvision.models.resnet101()\nmodel_conv.load_state_dict(torch.load('../input/pytorch-pretrained-models/resnet101-5d3b4d8f.pth'))\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(2048, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model_conv2 = torchvision.models.resnet50()\nmodel_conv2.load_state_dict(torch.load('../input/pytorch-pretrained-models/resnet50-19c8e357.pth'))\nnum_ftrs2 = model_conv2.fc.in_features\nmodel_conv2.fc = nn.Linear(2048, 5)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model_conv3 = torchvision.models.vgg16()\nmodel_conv3.load_state_dict(torch.load('../input/vgg16/vgg16.pth'))\nmodel_conv3.classifier[6] = nn.Linear(4096,5)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model_conv4 = torchvision.models.densenet121()\nmodel_conv4.load_state_dict(torch.load('../input/pytorch-pretrained-image-models/densenet121.pth'))\nmodel_conv4.classifier = nn.Linear(1024, 5)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model_conv5 = torchvision.models.inception_v3()\nmodel_conv5.load_state_dict(torch.load('../input/pretrained-pytorch-models/inception_v3_google-1a9a5a14.pth'))\n# Handle the auxilary net\nnum_ftrs = model_conv5.AuxLogits.fc.in_features\nmodel_conv5.AuxLogits.fc = nn.Linear(num_ftrs, 5)\n# Handle the primary net\nnum_ftrs = model_conv5.fc.in_features\nmodel_conv5.fc = nn.Linear(num_ftrs,5)\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1_path = \"../input/aptos1/model_1.pt\"\nmodel2_path = \"../input/aptos1/model_2.pt\"\nmodel3_path = \"../input/aptos1/model_3.pt\"\nmodel4_path = \"../input/aptos1/model_4.pt\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model_conv, train_loader, valid_loader, criterion, optimizer, n_epochs=15, attempt=1):\n    model_conv.to(device)\n    valid_loss_min = np.Inf\n    patience = 5\n    # current number of epochs, where validation loss didn't increase\n    p = 0\n    # whether training should be stopped\n    stop = False\n\n    # number of epochs to train the model\n    for epoch in range(1, n_epochs+1):\n        print(time.ctime(), 'Epoch:', epoch)\n\n        train_loss = []\n        train_auc = []\n\n        for batch_i, (data, target) in enumerate(train_loader):\n\n            data, target = data.cuda(), target.cuda()\n\n            optimizer.zero_grad()\n            output = model_conv(data)\n            loss = criterion(output, target.float())\n            train_loss.append(loss.item())\n\n            a = target.data.cpu().numpy()\n            b = output[:,-1].detach().cpu().numpy()\n            # train_auc.append(roc_auc_score(a, b))\n            loss.backward()\n            optimizer.step()\n\n        model_conv.eval()\n        val_loss = []\n        val_auc = []\n        for batch_i, (data, target) in enumerate(valid_loader):\n            data, target = data.cuda(), target.cuda()\n            output = model_conv(data)\n\n            loss = criterion(output, target.float())\n\n            val_loss.append(loss.item()) \n            a = target.data.cpu().numpy()\n            b = output[:,-1].detach().cpu().numpy()\n            # val_auc.append(roc_auc_score(a, b))\n\n        # print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}, train auc: {np.mean(train_auc):.4f}, valid auc: {np.mean(val_auc):.4f}')\n        print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}.')\n\n        valid_loss = np.mean(val_loss)\n        scheduler.step(valid_loss)\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            torch.save(model_conv.state_dict(), 'model_{}.pt'.format(attempt))\n            valid_loss_min = valid_loss\n            p = 0\n\n        # check if validation loss didn't improve\n        if valid_loss > valid_loss_min:\n            p += 1\n            print(f'{p} epochs of increasing val loss')\n            if p > patience:\n                print('Stopping training')\n                stop = True\n                break        \n\n        if stop:\n            break\n    return model_conv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.SGD(model_conv.fc.parameters(), lr=0.01, momentum=0.99)\n#scheduler = CyclicLR(optimizer, base_lr=lr, max_lr=0.01, step_size=5, mode='triangular2')\nscheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=2, )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_resnet101 = train_model(model_conv, train_loader, valid_loader, criterion = criterion, \n                              optimizer = optimizer, n_epochs=15, attempt=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model_resnet50 = train_model(model_conv2, train_loader, valid_loader, criterion = criterion, \n                              optimizer = optimizer, n_epochs=15, attempt=2)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model_densenet121 = train_model(model_conv4, train_loader, valid_loader, criterion = criterion, \n                              optimizer = optimizer, n_epochs=15, attempt=4)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model_vgg16 = train_model(model_conv3, train_loader, valid_loader, criterion = criterion, \n                              optimizer = optimizer, n_epochs=15, attempt=3)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_inception = train_model(model_conv5, train_loader_inc, valid_loader_inc, criterion = criterion, \n#                              optimizer = optimizer, n_epochs=15, attempt=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(model, test_loader):\n    sub = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n    model.eval()\n    for (data, target, name) in test_loader:\n        data = data.cuda()\n        output = model(data)\n        output = output.cpu().detach().numpy()\n        for i, (e, n) in enumerate(list(zip(output, name))):\n            sub.loc[sub['id_code'] == n.split('/')[-1].split('.')[0], 'diagnosis'] = le.inverse_transform([np.argmax(e)])\n    print( \"done\")\n    return sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_resnet101_1 = test_model(model_resnet101, test_loader)\ntest_resnet101_2 = test_model(model_resnet101, test_loader)\ntest_resnet101_3 = test_model(model_resnet101, test_loader)\ntest_resnet101_4 = test_model(model_resnet101, test_loader)\ntest_resnet101_5 = test_model(model_resnet101, test_loader)\ntest_resnet101_6 = test_model(model_resnet101, test_loader)\ntest_resnet101_7 = test_model(model_resnet101, test_loader)\ntest_resnet101_8 = test_model(model_resnet101, test_loader)\ntest_resnet101_9 = test_model(model_resnet101, test_loader)\ntest_resnet101_10 = test_model(model_resnet101, test_loader)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = (test_resnet101_1.diagnosis + test_resnet101_2.diagnosis + test_resnet101_3.diagnosis + test_resnet101_4.diagnosis + test_resnet101_5.diagnosis \n              + test_resnet101_6.diagnosis + test_resnet101_7.diagnosis  \n               + test_resnet101_8.diagnosis + test_resnet101_9.diagnosis + test_resnet101_10.diagnosis) / 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coef = [0.5, 1.5, 2.5, 3.5]\n\nfor i, pred in enumerate(test_preds):\n    if pred < coef[0]:\n        test_preds[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        test_preds[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        test_preds[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        test_preds[i] = 3\n    else:\n        test_preds[i] = 4\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"../input/aptos2019-blindness-detection/sample_submission.csv\")\nsample.diagnosis = test_preds.astype(int)\nsample.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_resnet50 = test_model(model_resnet50, test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_densenet121 = test_model(model_densenet121, test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_vgg16 = test_model(model_vgg16, test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_inception = test_model(model_inception, test_loader_inc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"sub = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n\nmodel_conv.eval()\nfor (data, target, name) in test_loader:\n    data = data.cuda()\n    output = model_conv(data)\n    output = output.cpu().detach().numpy()\n    for i, (e, n) in enumerate(list(zip(output, name))):\n        sub.loc[sub['id_code'] == n.split('/')[-1].split('.')[0], 'diagnosis'] = le.inverse_transform([np.argmax(e)])\n        \nsub.to_csv('submission.csv', index=False)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub['diagnosis'].value_counts()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}