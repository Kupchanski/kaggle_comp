{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport itertools\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport random\nimport collections\nimport time","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\nimport random","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_everything(19)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Preprocessing\n\nThis preprocessing method is more careful with RAM usage, which avoids crashing the kernel when you switch from CPU to GPU."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_transaction = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\n\ntrain_identity = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\n\nsample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(train.shape)\nprint(test.shape)\n\ny_train = train['isFraud'].copy()\ndel train_transaction, train_identity, test_transaction, test_identity\ngc.collect()\n\n# Drop target, fill in NaNs\nX_train = train.drop('isFraud', axis=1)\nX_test = test.copy()\n\ndel train, test\ngc.collect()\n\nX_train = X_train.fillna(0)\nX_test = X_test.fillna(0)\n\n# Label Encoding\nfor f in X_train.columns:\n    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n        X_train[f] = lbl.transform(list(X_train[f].values))\n        X_test[f] = lbl.transform(list(X_test[f].values))   ","execution_count":6,"outputs":[{"output_type":"stream","text":"(590540, 433)\n(506691, 432)\nCPU times: user 1min 35s, sys: 12.9 s, total: 1min 48s\nWall time: 1min 48s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# RAM optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train_norm = scaler.fit_transform(X_train)\nX_test_norm = scaler.fit_transform(X_test)\ndel X_train, X_test\ngc.collect()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"21"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.reset_index(drop = True, inplace=True)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"%%time\nX_train_norm = reduce_mem_usage(X_train_norm)\nX_test_norm = reduce_mem_usage(X_test_norm)\"\"\"","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"'%%time\\nX_train_norm = reduce_mem_usage(X_train_norm)\\nX_test_norm = reduce_mem_usage(X_test_norm)'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GetData(Dataset):\n    def __init__(self, datatype = \"train\"):\n        self.datatype = datatype\n        if self.datatype == \"train\":\n            self.labels = torch.FloatTensor(y_train.values).reshape(-1,1)\n            self.features = torch.FloatTensor(X_train_norm)\n        else:\n            self.labels = np.zeros((X_test_norm.shape[0],1))\n            self.features = torch.FloatTensor(X_test_norm)\n            \n    def __len__(self):\n        return len(self.features)\n    \n    \n    def __getitem__(self, idx):\n        row = self.features[idx]\n        label = self.labels[idx]\n        \n        return row, label\n        ","execution_count":91,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = GetData(datatype = \"train\")\ntest_set = GetData(datatype = \"test\")\ntr, val = train_test_split(y_train, stratify= y_train, test_size = 0.2)\ntrain_sampler = SubsetRandomSampler(list(tr.index))\nvalid_sampler = SubsetRandomSampler(list(val.index))\nbatch_size = 500\nnum_workers = 0\n\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, \n                                           sampler = train_sampler,\n                                           num_workers = num_workers )\nvalid_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, \n                                           sampler = valid_sampler,\n                                           num_workers = num_workers )\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, \n                                          num_workers = num_workers)","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":90,"outputs":[{"output_type":"execute_result","execution_count":90,"data":{"text/plain":"(590540,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralFraud(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(X_train_norm.shape[1], 500)\n        self.relu1 = nn.ReLU()\n        self.dp1 = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(500, 2048)\n        self.relu2 = nn.ReLU()\n        self.dp2 = nn.Dropout(0.2)\n        self.fc3 = nn.Linear(2048, 512)\n        self.relu3 = nn.ReLU()\n        self.dp3 = nn.Dropout(0.2)\n        self.fc4 = nn.Linear(512, 64)\n        self.relu4 = nn.ReLU()\n        self.dp4 = nn.Dropout(0.2)\n        self.last_linear = nn.Linear(64, 1)\n        self.out_act = nn.Sigmoid()\n        \n        \n    def forward(self, input):\n        a1 = self.fc1(input)\n        h1 = self.relu1(a1)\n        drp1 = self.dp1(h1)\n        a2 = self.fc2(drp1)\n        h2 = self.relu2(a2)\n        drp2 = self.dp2(h2)\n        a3 = self.fc3(drp2)\n        h3 = self.relu3(a3)\n        drp3 = self.dp3(h3)\n        a4 = self.fc4(drp3)\n        h4 = self.relu4(a4)\n        drp4 = self.dp4(h4)\n        a5 = self.last_linear(drp4)\n        y = self.out_act(a5)\n        return y\n    \n    \n    def predict(self, x):\n        \n        pred = F.softmax(self.forward(x))\n        return torch.tensor(pred)\n      \n        \n        \n        ","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, train_loader, valid_loader, criterion, optimizer, n_epochs=15):\n    model.to(device)\n    valid_loss_min = np.Inf\n    patience = 5\n    # current number of epochs, where validation loss didn't increase\n    p = 0\n    # whether training should be stopped\n    stop = False\n\n    # number of epochs to train the model\n    for epoch in range(1, n_epochs+1):\n        print(time.ctime(), 'Epoch:', epoch)\n\n        train_loss = []\n        train_auc = []\n\n        for batch_i, (data, target) in enumerate(train_loader):\n\n            data, target = data.cuda(), target.cuda()\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target.float())\n            train_loss.append(loss.item())\n\n            a = target.data.cpu().numpy()\n            b = output[:,-1].detach().cpu().numpy()\n            #train_auc.append(roc_auc_score(a, b))\n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n        val_loss = []\n        val_auc = []\n        for batch_i, (data, target) in enumerate(valid_loader):\n            data, target = data.cuda(), target.cuda()\n            output = model(data)\n\n            loss = criterion(output, target.float())\n\n            val_loss.append(loss.item()) \n            a = target.data.cpu().numpy()\n            b = output[:,-1].detach().cpu().numpy()\n            #val_auc.append(roc_auc_score(a, b))\n\n        # print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}, train auc: {np.mean(train_auc):.4f}, valid auc: {np.mean(val_auc):.4f}')\n        print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}.')\n\n        valid_loss = np.mean(val_loss)\n        scheduler.step(valid_loss)\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            torch.save(model.state_dict(), 'model.pt')\n            valid_loss_min = valid_loss\n            p = 0\n\n        # check if validation loss didn't improve\n        if valid_loss > valid_loss_min:\n            p += 1\n            print(f'{p} epochs of increasing val loss')\n            if p > patience:\n                print('Stopping training')\n                stop = True\n                break        \n\n        if stop:\n            break\n    return model","execution_count":97,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = NeuralFraud()\nloss = nn.MSELoss()\n#loss = nn.BCELoss()\nlr = 0.001\nn_epochs = 50\noptimizer = optim.SGD(model.parameters(), lr = lr, momentum = 0.99)\n#optimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.1)\n#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.8, patience=2)","execution_count":143,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_model = train_model(model, train_loader, valid_loader, criterion = loss, \n                              optimizer = optimizer, n_epochs=n_epochs)","execution_count":141,"outputs":[{"output_type":"stream","text":"Sun Sep  8 17:49:54 2019 Epoch: 1\nEpoch 1, train loss: 0.1209, valid loss: 0.1085.\nValidation loss decreased (inf --> 0.108524).  Saving model ...\nSun Sep  8 17:50:04 2019 Epoch: 2\nEpoch 2, train loss: 0.1059, valid loss: 0.1024.\nValidation loss decreased (0.108524 --> 0.102445).  Saving model ...\nSun Sep  8 17:50:13 2019 Epoch: 3\nEpoch 3, train loss: 0.1021, valid loss: 0.1014.\nValidation loss decreased (0.102445 --> 0.101357).  Saving model ...\nSun Sep  8 17:50:22 2019 Epoch: 4\nEpoch 4, train loss: 0.0997, valid loss: 0.0959.\nValidation loss decreased (0.101357 --> 0.095889).  Saving model ...\nSun Sep  8 17:50:31 2019 Epoch: 5\nEpoch 5, train loss: 0.0978, valid loss: 0.0957.\nValidation loss decreased (0.095889 --> 0.095653).  Saving model ...\nSun Sep  8 17:50:40 2019 Epoch: 6\nEpoch 6, train loss: 0.0956, valid loss: 0.0944.\nValidation loss decreased (0.095653 --> 0.094377).  Saving model ...\nSun Sep  8 17:50:50 2019 Epoch: 7\nEpoch 7, train loss: 0.0939, valid loss: 0.0973.\n1 epochs of increasing val loss\nSun Sep  8 17:50:59 2019 Epoch: 8\nEpoch 8, train loss: 0.0921, valid loss: 0.0929.\nValidation loss decreased (0.094377 --> 0.092897).  Saving model ...\nSun Sep  8 17:51:08 2019 Epoch: 9\nEpoch 9, train loss: 0.0907, valid loss: 0.0998.\n1 epochs of increasing val loss\nSun Sep  8 17:51:17 2019 Epoch: 10\nEpoch 10, train loss: 0.0892, valid loss: 0.0886.\nValidation loss decreased (0.092897 --> 0.088559).  Saving model ...\nSun Sep  8 17:51:26 2019 Epoch: 11\nEpoch 11, train loss: 0.0874, valid loss: 0.0921.\n1 epochs of increasing val loss\nSun Sep  8 17:51:35 2019 Epoch: 12\nEpoch 12, train loss: 0.0864, valid loss: 0.0880.\nValidation loss decreased (0.088559 --> 0.088016).  Saving model ...\nSun Sep  8 17:51:44 2019 Epoch: 13\nEpoch 13, train loss: 0.0850, valid loss: 0.0864.\nValidation loss decreased (0.088016 --> 0.086438).  Saving model ...\nSun Sep  8 17:51:53 2019 Epoch: 14\nEpoch 14, train loss: 0.0838, valid loss: 0.0896.\n1 epochs of increasing val loss\nSun Sep  8 17:52:03 2019 Epoch: 15\nEpoch 15, train loss: 0.0823, valid loss: 0.0858.\nValidation loss decreased (0.086438 --> 0.085837).  Saving model ...\nSun Sep  8 17:52:12 2019 Epoch: 16\nEpoch 16, train loss: 0.0807, valid loss: 0.0865.\n1 epochs of increasing val loss\nSun Sep  8 17:52:21 2019 Epoch: 17\nEpoch 17, train loss: 0.0794, valid loss: 0.0846.\nValidation loss decreased (0.085837 --> 0.084645).  Saving model ...\nSun Sep  8 17:52:30 2019 Epoch: 18\nEpoch 18, train loss: 0.0774, valid loss: 0.0836.\nValidation loss decreased (0.084645 --> 0.083567).  Saving model ...\nSun Sep  8 17:52:39 2019 Epoch: 19\nEpoch 19, train loss: 0.0758, valid loss: 0.0829.\nValidation loss decreased (0.083567 --> 0.082885).  Saving model ...\nSun Sep  8 17:52:48 2019 Epoch: 20\nEpoch 20, train loss: 0.0743, valid loss: 0.0809.\nValidation loss decreased (0.082885 --> 0.080938).  Saving model ...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(model, test_loader):\n    result = np.array([])\n    sub = sample_submission\n    model.eval()\n    for (data, target) in test_loader:\n        data = data.cuda()\n        output = model(data)\n        output = output.cpu().detach().numpy()\n        result = np.concatenate((result, output), axis=None)\n    print( \"done\")\n    return result","execution_count":132,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = test_model(model, test_loader)","execution_count":133,"outputs":[{"output_type":"stream","text":"done\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['isFraud'] = output\nsample_submission.to_csv('NNfraud.csv')","execution_count":135,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}