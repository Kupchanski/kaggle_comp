{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport itertools\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport xgboost as xgb\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nimport random\nimport collections\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_everything(19)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Preprocessing\n\nThis preprocessing method is more careful with RAM usage, which avoids crashing the kernel when you switch from CPU to GPU."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_transaction = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\n\ntrain_identity = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\n\nsample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(train.shape)\nprint(test.shape)\n\ny_train = train['isFraud'].copy()\ndel train_transaction, train_identity, test_transaction, test_identity\ngc.collect()\n\n# Drop target, fill in NaNs\nX_train = train.drop('isFraud', axis=1)\nX_test = test.copy()\n\ndel train, test\ngc.collect()\n\nX_train = X_train.fillna(0)\nX_test = X_test.fillna(0)\n\n# Label Encoding\nfor f in X_train.columns:\n    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n        X_train[f] = lbl.transform(list(X_train[f].values))\n        X_test[f] = lbl.transform(list(X_test[f].values))   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RAM optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train_norm = scaler.fit_transform(X_train)\nX_test_norm = scaler.fit_transform(X_test)\ndel X_train, X_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.reset_index(drop = True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"%%time\nX_train_norm = reduce_mem_usage(X_train_norm)\nX_test_norm = reduce_mem_usage(X_test_norm)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FraudDataset(Dataset):\n    def __init__(self, train_set=None, train_labels=None, test_set=None, datatype = \"train\"):\n        self.datatype = datatype\n        if self.datatype == \"train\":\n            self.labels = torch.FloatTensor(train_labels.values).reshape(-1,1)\n            self.features = torch.FloatTensor(train_set)\n        else:\n            self.labels = np.zeros((test_set.shape[0],1))\n            self.features = torch.FloatTensor(test_set)\n            \n    def __len__(self):\n        return len(self.features)\n    \n    \n    def __getitem__(self, idx):\n        row = self.features[idx]\n        label = self.labels[idx]\n        \n        return row, label\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = FraudDataset( train_set = X_train_norm, train_labels = y_train, datatype = \"train\")\ntest_set = FraudDataset(test_set = X_test_norm, datatype = \"test\")\ntr, val = train_test_split(y_train, stratify= y_train, test_size = 0.2)\ntrain_sampler = SubsetRandomSampler(list(tr.index))\nvalid_sampler = SubsetRandomSampler(list(val.index))\nbatch_size = 1000\nnum_workers = 0\n\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, \n                                           sampler = train_sampler,\n                                           num_workers = num_workers )\nvalid_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, \n                                           sampler = valid_sampler,\n                                           num_workers = num_workers )\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, \n                                          num_workers = num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralFraud(nn.Module):\n    \n    def __init__(self, length):\n        super().__init__()\n        self.fc1 = nn.Linear(length, 4096)\n        self.relu1 = nn.ReLU()\n        self.dp1 = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(4096, 2048)\n        self.relu2 = nn.ReLU()\n        self.dp2 = nn.Dropout(0.2)\n        self.fc3 = nn.Linear(2048, 512)\n        self.relu3 = nn.ReLU()\n        self.dp3 = nn.Dropout(0.2)\n        self.bn1 = nn.BatchNorm1d(512)\n        self.fc4 = nn.Linear(512, 64)\n        self.relu4 = nn.ReLU()\n        self.dp4 = nn.Dropout(0.2)\n        self.last_linear = nn.Linear(64, 1)\n        self.out_act = nn.Sigmoid()\n        \n        \n    def forward(self, input):\n        a1 = self.fc1(input)\n        h1 = self.relu1(a1)\n        drp1 = self.dp1(h1)\n        a2 = self.fc2(drp1)\n        h2 = self.relu2(a2)\n        drp2 = self.dp2(h2)\n        a3 = self.fc3(drp2)\n        h3 = self.relu3(a3)\n        drp3 = self.dp3(h3)\n        bnl1 = self.bn1(drp3)\n        a4 = self.fc4(bnl1)\n        h4 = self.relu4(a4)\n        drp4 = self.dp4(h4)\n        a5 = self.last_linear(drp4)\n        y = self.out_act(a5)\n        return y\n    \n    \n    def predict(self, x):\n        \n        pred = F.softmax(self.forward(x))\n        return torch.tensor(pred)\n      \n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def roc_auc_score_FIXED(y_true, y_pred):\n    if len(np.unique(y_true)) == 1: # bug in roc_auc_score\n        return accuracy_score(y_true, np.rint(y_pred))\n    return roc_auc_score(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, train_loader, valid_loader, criterion, optimizer, n_epochs=15):\n    model.to(device)\n    valid_loss_min = np.Inf\n    patience = 5\n    # current number of epochs, where validation loss didn't increase\n    p = 0\n    # whether training should be stopped\n    stop = False\n\n    # number of epochs to train the model\n    for epoch in range(1, n_epochs+1):\n        print(time.ctime(), 'Epoch:', epoch)\n\n        train_loss = []\n        train_auc = []\n\n        for batch_i, (data, target) in enumerate(train_loader):\n\n            data, target = data.cuda(), target.cuda()\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target.float())\n            train_loss.append(loss.item())\n\n            a = target.data.cpu().numpy()\n            b = output[:,-1].detach().cpu().numpy()\n            train_auc.append(roc_auc_score_FIXED(a, b))\n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n        val_loss = []\n        val_auc = []\n        for batch_i, (data, target) in enumerate(valid_loader):\n            data, target = data.cuda(), target.cuda()\n            output = model(data)\n\n            loss = criterion(output, target.float())\n\n            val_loss.append(loss.item()) \n            a = target.data.cpu().numpy()\n            b = output[:,-1].detach().cpu().numpy()\n            val_auc.append(roc_auc_score_FIXED(a, b))\n\n        # print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}, train auc: {np.mean(train_auc):.4f}, valid auc: {np.mean(val_auc):.4f}')\n        print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}, train_auc: {np.mean(train_auc):.4f}, val_auc: {np.mean(val_auc):.4f}')\n\n        valid_loss = np.mean(val_loss)\n        scheduler.step(valid_loss)\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            torch.save(model.state_dict(), 'model.pt')\n            valid_loss_min = valid_loss\n            p = 0\n\n        # check if validation loss didn't improve\n        if valid_loss > valid_loss_min:\n            p += 1\n            print(f'{p} epochs of increasing val loss')\n            if p > patience:\n                print('Stopping training')\n                stop = True\n                break        \n\n        if stop:\n            break\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = NeuralFraud(length = X_train_norm.shape[1])\nloss = nn.MSELoss()\n#loss = nn.BCELoss()\nlr = 0.001\nn_epochs = 50\noptimizer = optim.SGD(model.parameters(), lr = lr, momentum = 0.99)\n#optimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.1)\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.8, patience=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_model = train_model(model, train_loader, valid_loader, criterion = loss, \n                              optimizer = optimizer, n_epochs=n_epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(model, test_loader):\n    result = np.array([])\n    sub = sample_submission\n    with torch.no_grad():\n        model.eval()\n        for (data, target) in test_loader:\n            data = data.cuda()\n            output = model(data)\n            output = output.cpu().detach().numpy()\n            result = np.concatenate((result, output), axis=None)\n        print( \"done\")\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = test_model(model, test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['isFraud'] = output\nsample_submission.to_csv('NNfraud.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}